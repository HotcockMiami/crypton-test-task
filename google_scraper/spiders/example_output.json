[
{"name": "Scrapy | A Fast and Powerful Scraping and Web Crawling Framework", "url": "https://scrapy.org/", "desc": "pip install scrapy cat > myspider.py <<EOF import scrapy class BlogSpider( scrapy.Spider): name = 'blogspider' start_urls = ['https://blog.scrapinghub.com'] def ...\n"},
{"name": "Scrapy Tutorial — Scrapy 2.4.0 documentation - Scrapy Docs", "url": "https://docs.scrapy.org/en/latest/intro/tutorial.html", "desc": "Creating a new Scrapy project. Writing a spider to crawl a site and extract data. Exporting the scraped data using the command line. Changing ...\n\nProgramming languages: "},
{"name": "Scrapy 2.4 documentation — Scrapy 2.4.0 documentation", "url": "https://docs.scrapy.org/en/latest/", "desc": "Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. It can be used for a ..."},
{"name": "Парсинг сайта используя Scrapy | Scrapy примеры кода - Python 3", "url": "https://python-scripts.com/scrapy-example", "desc": "Главное отличие между Scrapy и другими популярными библиотеками, такими как Requests или BeautifulSoup, заключается в том, что он позволяет  ..."},
{"name": "Как создать парсер на python c помощью Scrapy. Пошагово ...", "url": "https://pythonru.com/biblioteki/sozdanie-parserov-s-pomoshhju-scrapy-i-python", "desc": "Scrapy использует Spiders — автономных сканеров с определенным набором инструкций. С помощью фреймворка легко разработать ..."},
{"name": "Scrapy: собираем данные и сохраняем в базу данных / Хабр", "url": "https://habr.com/ru/post/308660/", "desc": "Решение. Для решения задачи я использовал Python 2.7, Scrapy 1.1 Sqlalchemy 1, Sqlite. Установил все как описано в документации. В ..."},
{"name": "Собираем данные с помощью Scrapy / Хабр - Habr.com", "url": "https://habr.com/ru/post/115710/", "desc": "Запуск. Исходный код можно взять тут, для запуска перейдите в папку с проектом и наберите в консоли scrapy crawl abitur --set ..."},
{"name": "Scrapy — Википедия", "url": "https://ru.wikipedia.org/wiki/Scrapy", "desc": "Scrapy (читается как \"скрэй-пай\") – это бесплатный фреймворк для веб- краулинга находящийся в открытом доступе, который написан на языке ..."},
{"name": "Библиотека для парсинга сайта Scrapy", "url": "https://tyvik.ru/posts/parsing-scrapy/", "desc": "You can start your first spider with: cd habr scrapy genspider ... Для запуска перейдём в каталог с scrapy.cfg и выполним scrapy crawl ..."},
{"name": "Пишем простой парсер на Scrapy | Блог python программиста", "url": "https://pycoder.ru/make-simple-spider-scrapy/", "desc": "1 # python 3 2 import scrapy 3 from urllib.parse import urljoin 4 5 6 class PycoderSpider(scrapy.Spider): 7 name = \"pycoder\" 8 start_urls = [ 9 ..."}
]